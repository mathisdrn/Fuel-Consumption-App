{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7l/wwrkhf0515x8dl_scksshbc00000gn/T/ipykernel_34881/2577772231.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['TRANSMISSION'] = df['TRANSMISSION'].str.replace(r'\\d+$', '')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/fuel_consumption.csv', parse_dates=['YEAR'])\n",
    "# Change Type of fuel to name\n",
    "df['FUEL'] = df['FUEL'].replace({'X': 'Regular gasoline', 'Z': 'Premium gasoline', 'D': 'Diesel', 'E': 'Ethanol (E85)', 'N': 'Natural Gas'})\n",
    "# Extract last caracter of transmission as number of gears\n",
    "# ie. 816 cars have continuous variable transmission and don't have a number of gears\n",
    "df['GEARS'] = df['TRANSMISSION'].str.extract(r'(\\d+)$', expand=False)\n",
    "df['TRANSMISSION'] = df['TRANSMISSION'].str.replace(r'\\d+$', '')\n",
    "df['TRANSMISSION'] = df['TRANSMISSION'].replace({'A': 'Automatic', 'AM': 'Automated manual', 'AS': 'Automatic with select shift', 'AV': 'Continuously variable', 'M': 'Manual'})\n",
    "# Rename FUEL CONSUMPTION to CITY (L/100 km)\n",
    "df = df.drop(columns=['COMB (mpg)'], axis = 1)\n",
    "df = df.rename(columns={'FUEL CONSUMPTION': 'CITY (L/100 km)'})\n",
    "df['MAKE'] = df['MAKE'].str.capitalize()\n",
    "\n",
    "# Uniformize vehicle class\n",
    "df['VEHICLE CLASS'] = df['VEHICLE CLASS'].str.capitalize()\n",
    "df.loc[df['VEHICLE CLASS'].str.contains('Pickup truck'), 'VEHICLE CLASS'] = 'Pickup truck'\n",
    "df.loc[df['VEHICLE CLASS'].str.contains('Station wagon'), 'VEHICLE CLASS'] = 'Station wagon'\n",
    "df.loc[df['VEHICLE CLASS'].str.contains('Suv'), 'VEHICLE CLASS'] = 'SUV'\n",
    "df.loc[df['VEHICLE CLASS'].str.contains('Van'), 'VEHICLE CLASS'] = 'Van'\n",
    "\n",
    "# rename YEAR, VEHICLE CLASS, MAKE, MODEL, ENGINE SIZE, CYLINDERS, TRANSMISSION, FUEL, CITY (L/100 km), HWY (L/100 km), COMB (L/100 km), CO2 EMISSIONS (g/km)\n",
    "df = df.rename(columns={'YEAR': 'Release year', 'GEARS' : 'Gears', 'VEHICLE CLASS': 'Vehicle class', 'MAKE': 'Make', 'MODEL': 'Model', 'ENGINE SIZE': 'Engine size (L)', 'CYLINDERS': 'Cylinders', 'TRANSMISSION': 'Transmission', 'FUEL': 'Fuel', 'CITY (L/100 km)': 'City (L/100 km)', 'COMB (L/100 km)': 'Mixed consumption (L/100 km)', 'HWY (L/100 km)': 'Highway (L/100 km)', 'EMISSIONS': 'CO2 emissions (g/km)'})\n",
    "df['Release year'] = df['Release year'].dt.year\n",
    "# Target - Features\n",
    "X = df[['Make', 'Release year', 'Vehicle class', 'Fuel', 'Transmission', 'Gears', 'Engine size (L)', 'Cylinders']]\n",
    "Y = df[['CO2 emissions (g/km)', 'Mixed consumption (L/100 km)', 'City (L/100 km)', 'Highway (L/100 km)']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22556, 87)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "numerical = X.select_dtypes(include=['int64', 'float64']).columns.values.tolist()\n",
    "categorical = X.select_dtypes(include=['object']).columns.values.tolist()\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers = [\n",
    "    ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical),\n",
    "    ('numerical', StandardScaler(), numerical)\n",
    "    ])\n",
    "\n",
    "X_fitted = preprocessor.fit_transform(X)\n",
    "X_fitted.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "mi_co2 = mutual_info_regression(X_fitted, Y['CO2 emissions (g/km)'])\n",
    "mi_mixed = mutual_info_regression(X_fitted, Y['Mixed consumption (L/100 km)'])\n",
    "mi_city = mutual_info_regression(X_fitted, Y['City (L/100 km)'])\n",
    "mi_highway = mutual_info_regression(X_fitted, Y['Highway (L/100 km)'])\n",
    "\n",
    "cat_col = preprocessor.named_transformers_['categorical'].get_feature_names_out()\n",
    "num_col = preprocessor.named_transformers_['numerical'].get_feature_names_out()\n",
    "col = np.concatenate((cat_col, num_col))\n",
    "mi_targets = pd.DataFrame({'Features': col, 'MI_co2': mi_co2, 'MI_mixed': mi_mixed, 'MI_city': mi_city, 'MI_highway': mi_highway})\n",
    "\n",
    "mi_dict = {\n",
    "    'CO2 emissions (g/km)' : 'MI_co2',\n",
    "    'Mixed consumption (L/100 km)' : 'MI_mixed',\n",
    "    'City (L/100 km)' : 'MI_city',\n",
    "    'Highway (L/100 km)' : 'MI_highway'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-908362dc891449c7b887b48df4e54925\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-908362dc891449c7b887b48df4e54925\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-908362dc891449c7b887b48df4e54925\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0a6963099b72d144a57925b24c39d193\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"MI_co2\", \"title\": \"Mutual Information Score for CO2 emissions (g/km)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Features\", \"sort\": \"-x\", \"type\": \"nominal\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-0a6963099b72d144a57925b24c39d193\": [{\"Features\": \"Engine size (L)\", \"MI_co2\": 0.9966405526743611, \"MI_mixed\": 0.9068819747953842, \"MI_city\": 0.9955756443201014, \"MI_highway\": 0.7467868203279138}, {\"Features\": \"Cylinders\", \"MI_co2\": 0.596613044549198, \"MI_mixed\": 0.5615671267294859, \"MI_city\": 0.6217258045631995, \"MI_highway\": 0.41823453229743945}, {\"Features\": \"Release year\", \"MI_co2\": 0.2928701972702856, \"MI_mixed\": 0.0889234971146804, \"MI_city\": 0.11060783971103838, \"MI_highway\": 0.09627094625697152}, {\"Features\": \"Vehicle class_Pickup truck\", \"MI_co2\": 0.08448046972646828, \"MI_mixed\": 0.0715485456939835, \"MI_city\": 0.06271299208917336, \"MI_highway\": 0.08905382743859569}, {\"Features\": \"Transmission_Automatic\", \"MI_co2\": 0.0744615088156928, \"MI_mixed\": 0.07483189933275103, \"MI_city\": 0.07113464592906293, \"MI_highway\": 0.06342395505447174}, {\"Features\": \"Transmission_Continuously variable\", \"MI_co2\": 0.06380176348053834, \"MI_mixed\": 0.06081007227506929, \"MI_city\": 0.06797353206371803, \"MI_highway\": 0.03663508078777156}, {\"Features\": \"Fuel_Regular gasoline\", \"MI_co2\": 0.0560474264874693, \"MI_mixed\": 0.05694499496298455, \"MI_city\": 0.06450469381968826, \"MI_highway\": 0.04216796793062505}, {\"Features\": \"Gears_8\", \"MI_co2\": 0.05435153054585151, \"MI_mixed\": 0.018752094884963988, \"MI_city\": 0.02352534960465147, \"MI_highway\": 0.02049160784584303}, {\"Features\": \"Fuel_Premium gasoline\", \"MI_co2\": 0.05337083627706263, \"MI_mixed\": 0.04501974108362794, \"MI_city\": 0.04282685646387563, \"MI_highway\": 0.03937503557401145}, {\"Features\": \"Gears_4\", \"MI_co2\": 0.05258715227603994, \"MI_mixed\": 0.03778138790917307, \"MI_city\": 0.031543491851667715, \"MI_highway\": 0.030075357796713886}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "    \n",
    "def plot_mi(mi_targets, target):\n",
    "    return alt.Chart(mi_targets.sort_values(by=mi_dict[target], ascending=False).head(10)).mark_bar().encode(\n",
    "        y = alt.Y('Features:N', sort='-x'),\n",
    "        x = alt.X(f'{mi_dict[target]}:Q', title = f'Mutual Information Score for {target}'),\n",
    "    )\n",
    "\n",
    "# choice = st.selectbox('Select a target', ('CO2 emissions (g/km)', 'Mixed consumption (L/100 km)', 'City (L/100 km)', 'Highway (L/100 km)'))\n",
    "choice = np.random.choice(list(mi_dict.keys()))\n",
    "plot_mi(mi_targets, choice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe, space_eval\n",
    "from hyperopt.pyll.base import scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor())],\n",
    "    memory = cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'regressor__max_depth': scope.int(hp.quniform('max_depth', 3, 18, 1)),\n",
    "    'regressor__n_estimators': hp.choice('n_estimators', np.arange(100, 1000, 100)),\n",
    "    'regressor__learning_rate': hp.choice('learning_rate', np.geomspace(0.01, 0.3, 10)),\n",
    "    'regressor__gamma': hp.uniform ('gamma', 1, 9),\n",
    "    'regressor__reg_alpha' : hp.quniform('reg_alpha', 40, 180, 1),\n",
    "    'regressor__reg_lambda' : hp.uniform('reg_lambda', 0, 1),\n",
    "    'regressor__subsample' : hp.uniform('subsample', 0.5, 1),\n",
    "    'regressor__colsample_bytree' : hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'regressor__colsample_bylevel' : hp.uniform('colsample_bylevel', 0.4, 1),\n",
    "    'regressor__min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "}\n",
    "\n",
    "def objective(space):\n",
    "    # Set pipeline parameters\n",
    "    pipeline.set_params(**space)\n",
    "    cross_val = cross_val_score(pipeline, X, Y['CO2 emissions (g/km)'], verbose = 1, cv=3, scoring='r2', n_jobs=-1)\n",
    "    r2 = cross_val.mean()    \n",
    "    print (\"SCORE:\", r2)\n",
    "    return {'loss': -r2, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                 \n",
      "0.8166062313444541                                     \n",
      "  1%|          | 1/100 [00:02<03:58,  2.41s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.808551887524612                                                                 \n",
      "  2%|▏         | 2/100 [00:04<03:58,  2.44s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.7936807245507286                                                                \n",
      "  3%|▎         | 3/100 [00:06<03:07,  1.93s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.8165130975642093                                                                \n",
      "  4%|▍         | 4/100 [00:10<04:35,  2.87s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.3s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.7869049165837843                                                                \n",
      "  5%|▌         | 5/100 [00:11<03:17,  2.08s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.7906791538926338                                                                \n",
      "  6%|▌         | 6/100 [00:12<02:46,  1.77s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.7915963795794521                                                                \n",
      "  7%|▋         | 7/100 [00:14<03:00,  1.94s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.3s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.7752420712744673                                                                \n",
      "  8%|▊         | 8/100 [00:18<03:59,  2.60s/trial, best loss: -0.8166062313444541]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.0s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.8224541274381054                                                                \n",
      "  9%|▉         | 9/100 [00:26<06:29,  4.28s/trial, best loss: -0.8224541274381054]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    8.0s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.8255409652871831                                                                \n",
      " 10%|█         | 10/100 [00:36<09:11,  6.13s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.2s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8228209859117963                                                                 \n",
      " 11%|█         | 11/100 [00:41<08:13,  5.55s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.2s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8038030525237487                                                                 \n",
      " 12%|█▏        | 12/100 [00:53<11:02,  7.53s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.0s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8218540268627947                                                                 \n",
      " 13%|█▎        | 13/100 [00:58<09:45,  6.73s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.9s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8197307605525456                                                                 \n",
      " 14%|█▍        | 14/100 [01:09<11:38,  8.12s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   11.3s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8188710491860025                                                                 \n",
      " 15%|█▌        | 15/100 [01:13<09:52,  6.97s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    4.3s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.7966262399175509                                                                 \n",
      " 16%|█▌        | 16/100 [01:17<08:22,  5.99s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.7s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8185835280884154                                                                 \n",
      " 17%|█▋        | 17/100 [01:27<09:59,  7.23s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.1s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8150479911485292                                                                 \n",
      " 18%|█▊        | 18/100 [01:38<11:25,  8.36s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   11.0s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8229405047855476                                                                 \n",
      " 19%|█▉        | 19/100 [01:49<12:26,  9.22s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   11.2s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8131707914773338                                                                 \n",
      " 20%|██        | 20/100 [01:53<10:00,  7.50s/trial, best loss: -0.8255409652871831]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.5s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8259066013454098                                                                 \n",
      " 21%|██        | 21/100 [02:07<12:36,  9.58s/trial, best loss: -0.8259066013454098]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   14.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.823819106225918                                                                  \n",
      " 22%|██▏       | 22/100 [02:17<12:24,  9.54s/trial, best loss: -0.8259066013454098]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8223130224222666                                                                 \n",
      " 23%|██▎       | 23/100 [02:26<12:03,  9.39s/trial, best loss: -0.8259066013454098]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    9.0s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.821960202202904                                                                  \n",
      " 24%|██▍       | 24/100 [02:32<10:40,  8.42s/trial, best loss: -0.8259066013454098]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    6.2s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8266621848278667                                                                 \n",
      " 25%|██▌       | 25/100 [02:44<12:01,  9.63s/trial, best loss: -0.8266621848278667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   12.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.825146860369808                                                                  \n",
      " 26%|██▌       | 26/100 [02:52<11:14,  9.11s/trial, best loss: -0.8266621848278667]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.9s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                             \n",
      "0.8280510797345363                                                                 \n",
      " 27%|██▋       | 27/100 [03:03<11:33,  9.50s/trial, best loss: -0.8280510797345363]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   10.4s finished\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "result = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials,\n",
    "                        verbose = 1,\n",
    "                        show_progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__colsample_bylevel': 0.6141123893478884,\n",
       " 'regressor__colsample_bytree': 0.7544294982956999,\n",
       " 'regressor__gamma': 2.404609402359236,\n",
       " 'regressor__learning_rate': 0.045341755991148446,\n",
       " 'regressor__max_depth': 17,\n",
       " 'regressor__min_child_weight': 0.0,\n",
       " 'regressor__n_estimators': 900,\n",
       " 'regressor__reg_alpha': 40.0,\n",
       " 'regressor__reg_lambda': 0.2587299493111584,\n",
       " 'regressor__subsample': 0.8780109941605825}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams = space_eval(space, result)\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   7.0s\n",
      "[CV] END .................................................... total time=   7.0s\n",
      "[CV] END .................................................... total time=   7.1s\n",
      "R2 Score : 84.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    7.1s finished\n"
     ]
    }
   ],
   "source": [
    "pipeline.set_params(**best_hyperparams)\n",
    "\n",
    "result = cross_val_score(pipeline, X, Y['CO2 emissions (g/km)'], verbose = 2, cv=3, scoring='r2', n_jobs=-1)\n",
    "# pipeline.named_steps['regressor'].set_params(**best_param)\n",
    "print(f'R2 Score : {round(result.mean()*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f433cee6efbc47c6089c6c5913bf9f9acbafe890209a746bcd45e5a156a481f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
